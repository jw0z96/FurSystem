%%% template.tex
%%%
%%% This LaTeX source document can be used as the basis for your technical
%%% paper or abstract. Intentionally stripped of annotation, the parameters
%%% and commands should be adjusted for your particular paper - title,
%%% author, article DOI, etc.
%%% The accompanying ``template.annotated.tex'' provides copious annotation
%%% for the commands and parameters found in the source document. (The code
%%% is identical in ``template.tex'' and ``template.annotated.tex.'')

\documentclass[]{acmsiggraph}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\TOGonlineid{45678}
\TOGvolume{0}
\TOGnumber{0}
\TOGarticleDOI{0}
\TOGprojectURL{}
\TOGvideoURL{}
\TOGdataURL{}
\TOGcodeURL{}
\usepackage{color}
%\definecolor{red}{rgb}{0.9, 0.17, 0.31}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{glsllst} % My own package providing markup listing for glsl
\usepackage{rmlst}   % My own package providing markup listing for renderman
\usepackage{amsmath}
\usepackage{hyperref}

\lstset{
	backgroundcolor=\color[rgb]{0.95, 0.95, 0.95},
	tabsize=3,
	%rulecolor=,
	basicstyle=\footnotesize\ttfamily,
	upquote=true,
	aboveskip={1.5\baselineskip},
	columns=fixed,
	showstringspaces=false,
	extendedchars=true,
	breaklines=true,
	prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
	frame=none,
	aboveskip=15pt,
	belowskip=8pt,
	captionpos=t,
	showtabs=false,
	showspaces=false,
	showstringspaces=false,
	identifierstyle=\ttfamily,
	%keywordstyle=\color{red}\bfseries,
	%keywordstyle=[1]\bfseries\color{syntaxBlue},
	%keywordstyle=[2]\bfseries\color{syntaxRed},
	%keywordstyle=[3]\color{blue}\bfseries,
	%keywordstyle=[4]\bfseries\color{syntaxBlue},
	commentstyle=\color[rgb]{0.082,0.639,0.082},
	keywordstyle=[1]\bfseries\color[rgb]{0,0,0.75},
	keywordstyle=[2]\bfseries\color[rgb]{0.5,0.0,0.0},
	keywordstyle=[3]\bfseries\color[rgb]{0.127,0.427,0.514},
	keywordstyle=[4]\bfseries\color[rgb]{0.4,0.4,0.4},
	stringstyle=\color[rgb]{0.639,0.082,0.082},
}

\title{Innovations Report: Procedural Fur System}

\author{Joe Withers\thanks{e-mail:joewithers96@gmail.com}\\National Centre for Computer Animation}
\pdfauthor{Joe Withers}

\keywords{rendering}

\begin{document}

\maketitle

\begin{abstract}
For this project I developed a procedural fur system, with the aim of exploring the feasibility of offloading computation onto the GPU within artist tools. The final artefact is an application which serves to interface with the fur system API which I have developed. This report primarily documents the implementation of the API, as well as my findings.
\end{abstract}

\section{Introduction} \label{sec:introduction}
Introduction Text.
\subsection{Related Work} \label{sec:related}
nvidia hairworks

\subsection{Existing Solutions} \label{sec:existing}
Whilst many larger companies opt to develop their own software for handling fur, such as MPC's Furtility \cite{furtility}, there are a number of commercially available solutions that are also widely used in production.

The most popular of these is XGen, originally developed by Walt Disney Animation Studios, which has been included in Autodesk's Maya since 2014. XGen uses a 'Collection' and 'Description' paradigm; Descriptions store user controlled parameters which affect fur primitives (curves for example) on a select area of a mesh, and Collections act as a container for these Descriptions. There are two primary methods offered for distributing primitives on a mesh, Guide Curves can be used to manually control the placement and shape of primitives by placing 'Guides' on the mesh surface, whereas 'Groomable Splines' randomly distirbutes splines over the mesh surface which can be manipulated in real time using viewport manipulators that mimic the brushing and styling of fur. In both modes, 'modifiers' can be added to the modifier stack to further adjust the visual outcome, adding features such as clumping, noise, and coiling. Attributes within these modifiers can be further controlled using expressions or texture maps.

Another commercially available solution is Peregrine*Labs' Yeti \cite{yeti}, which is also offered as a plugin within Autodesk's Maya. Yeti offers a more procedural approach, giving the user a node graph interface in which to construct the desired look from individual components. For example, the most simple usage requires the user to first create a 'scatter' node to distribute points on the mesh surface, and then combine it with a 'grow' node to extrude curves from these points. Whilst at first this may seem unintuitive when compared to XGen, it offers greater flexibility and avoids the pitfalls associated with a destructive workflow.

Offerering even even more flexibility, recent versions of SideFX's Houdini include hair and fur operator nodes, which create predefined node networks for the generation of hair and fur. These networks use standard Houdini nodes internally, so experienced Houdini users are intuitively able to create the visual outcome they desire, using tools they already know. However, it may be quite unintuitive for asset artists (those who would be using the tool, Groom artists?), who are not used to Houdini's heavily procedural workflow.

\subsection{GPU Acceleration} \label{sec:existingGPU}
Whilst it is not clear to what extent each of these solutions make use of GPU acceleration, they all perform fast enough to allow the user to manipulate them interactively. I therefore decided to monitor the CPU and GPU usage using \verb|htop| and \verb|nvidia-smi| respectively, before and after adding XGen content to a simple maya scene, to determine where the majority of data was being computed.

After applying the default XGen description onto a simple sphere with 760 triangles, there was no noticeable increase in both GPU utilisation and GPU memory usage. Increasing the density of the primitives from 1.0 to 10000.0 saw an increase of VRAM usage of roughly 350MiB, which I would attribute to storing the primitives in a buffer on the GPU, but there was no discernable increase in GPU utilisation. Increasing the density further to 10,000 saw a noticable spike in CPU usage, hitting 100 percent across two threads, leading me to believe that the primitive distribution computation is being done on the CPU.

However, when applying modifiers to the XGen description I noticed a small increase of roughly 2MiB in VRAM usage for the first modifier, yet no further increases for modifiers added after that. As this increase is quite small I would attribute it to storing the modifier attributes on the GPU, though I still noticed spikes in CPU usage when recalculating the XGen description once the modifier was added, which makes it inconclusive as to whether XGen uses any kind of GPU acceleration.

% on maya load: CPU up to 8 percent when moving mouse GPU very low but 40 percent when moving viewport 42MiB
% before xgen on sphere 36mib
% xgen on sphere density 1.0 36mib GPU
% xgen on sphere density 100.0 40mib GPU
% xgen CPU spiked up to 100 on a single thread when changing density
% xgen on sphere density 1000.0 56mib GPU
% xgen noise on sphere density 1000.0 63mib GPU, CPU spiked but only to 20%
% xgen on sphere density to 10,000 caused spike on 2 threads

\section{Implementation} \label{sec:implementation}
From my research it was clear that there is an apparent lack of standalone software for authoring fur; it makes sense that existing fur software are developed as software plugins, allowing the tool to make use of their host DCCs existing functionality.

However, by developing the system as a simple API one could make it DCC agnostic, which is why I chose to develop my system as a pairing of a simple API with a standalone tool which interfaces with it. By developing a simple API it could allow for future implementations as plugins within DCCs, providing the data exchange formats are compatible with the host DCC.

\subsection{Resources} \label{sec:resources}
I decided to develop the API side of the fur system using C++, primarly as it most commonly used when developing computationally heavy artist tools, but also because it is the language I am most comfortable using. I opted to use OpenGL over other APIs (CUDA, OpenCL) for offloading of computation onto the GPU, simply because my final artefact is a tool with a graphical interface, and OpenGL is capable of handling both arbitary computation using compute shaders and rendering of geometry simultaneously.

To handle the user interface I used the Qt framework within C++. Qt is commonly used for artist tools within visual effects as it is cross-platform, and applications can be configured to run within other applications that make use of it, such as Autodesk Maya.

I wanted to include a node-graph style interface within my application, as it is commonly used within existing artist tools (Autodesk Maya, Unreal Engine), and would encourage modularity within my API. Qt does not natively provide this kind of interface, so I made use of NodeEditor \cite{Pinaev2017}, an existing Qt-based library that provides this functionality.

\subsection{Design} \label{sec:design}
From looking at existing fur systems I was able determine that my simplified fur system would need to consist of the following components:

\begin{itemize}
	\item Geometry Loaders - These are responsible for loading user specified geometry. Example Geometry Loaders could allow for the parsing of Wavefront OBJ files.
	\item Distributors - These are responsible for the distribution of curves onto user specified geometry. User controllable parameters could include density (curve count), distribution pattern (random, uniform), and curve length. These parameters could potentially be controlled by texture inputs.
	\item Operators - These are responsible for manipulation of the curves to achieve the desired look. Example operators could provide bending, clumping, or randomisation of input curves.
	\item Renderers - These are responsible for the rendering of curves into the application viewport. Example renderers could provide mesh, cuves as lines, or curves as ribbons rendering functionality. User controllable parameters could provide controls for the shading model in use, as well as control of the base and tip widths when rendering curve ribbons for example.
\end{itemize}

Whilst the list of components specified above provide the required functionality for a standalone tool, they do not provide any functionality for exporting fur for use in a broader pipeline. I chose to omit this functionality to limit the scope of this assignment, but the ability to export hair curves as alembic would be desirable, as alembic is a widely adopted format that allows for the storage of multiple different types of curve geometry. Another candidate file type would be RenderMan's RIB format, which would allow for direct rendering of the hair curves in any RenderMan compliant renderer.

\subsection{Development} \label{sec:development}

In this section I will explain the development of each of the major components, not necessarily in chronological order, but in the order regarding to how their data is passed through the system.

% write about distributing https://stackoverflow.com/questions/9294316/
% distribute-points-on-mesh-according-to-density

% write about GPU

\subsubsection{Mesh Loading} \label{sec:objLoading}
% The first problem I tackled was that of loading mesh geometry into the system, and storing it in a Shader Storage Buffer Object (SSBO) for later use in a compute shader. I opted to implement a Wavefront OBJ loader as they are (deceptively) simple to parse, consisting of a list of vertex positions, vertex normals, vertex texture coordinates, and faces defined as a list of indices. I created an OBJ loader node using the NodeEditor library, which parses

The first problem I tackled was that of loading mesh geometry into the system, in such a way that would allow for later computation on both the GPU and CPU. I opted to implement a Wavefront OBJ loader as they are (deceptively) simple to parse, consisting of a list of vertex positions, vertex normals, vertex texture coordinates, and faces as defined by a list of indices. This data structure formed the basis of my 'Mesh' class. Using the NodeEditor library I then created a node which loads OBJ files, and outputs the 'Mesh' object through it's output data port.

\subsubsection{Curve Distributors} \label{sec:distributors}

In order to generate curves for the system to manipulate, it was necessary to create a node that handles the distribution of curves onto the surface of a mesh. This node needs to take 'Mesh' object data as input, and output 'Curves' object data. A 'Curves' object was implemented which consists an array of 'Curve' objects, which in turn consist of an array 5 vertex positions that construct the curve. Distributor nodes would also need to alternate between performing the distribution process on the CPU or on the GPU, which would in turn affect whether the node outputs a 'Curves' object, or an ID for where the curves data is stored on the GPU.

With these parameters in mind I decided to implement an abstract distributor node class, which contains a virtual function for performing the distribution, and handles the callbacks for when input data is changed and the distribution needs to be updated. This makes the system somewhat extensible, allowing for different distribution patterns to be implemented with ease. The node's data type was also extented to be able to store either 'Curves' objects from the CPU, or an ID for an OpenGL buffer object, with an enumerated value to identify which of these is currently in use. This not only allows the distributor to alternate between CPU and GPU computation arbitrarily, but also allows nodes recieving this data to process it accordingly.

There are many different methods one could use to distribute points on an abritrary mesh, however for replicating creature fur it is desirable to choose a method that distributes primitives at random positions across the surface, yet roughly evenly spaced from neighboring primitives. A popular method used to achieve this kind of distribution is referred to as 'Dart Throwing', which relies on checking the distance to neighboring samples after a new sample has been generated, and discarding the sample if the samples are too close. Whilst these kinds of methods produce good results, they can be inefficient as in certain situations many samples may be generated and rejected, before a sample is accepted. An optimisation for this is described in \textit{Dart Throwing on Surfaces} \cite{dartThrowing}, which relies on removing areas of the mesh that are already covered by a sample, by means of triangle subdivision.

Unfortunately, parallelizing dart thowing methods is not trivial, making them unsuitable for my desired usage of OpenGL compute shaders. Whilst sampling methods suitable for parallel processing do exist, such as those described in \textit{Parallel Poisson Disk Sampling with Spectrum Analysis on Surfaces} \cite{parallelPoisson}, I instead opted to implement a naive random samling method as it was much easier to parallelize.

\begin{enumerate}
\item Generate a uniform random number in the range [0.0 - 1.0].
\end{enumerate}






The most common way of storing OBJ data in OpenGL buffers, as described in \cite{objLoading}, is to use a \verb|GL_ARRAY_BUFFER| object to store the vertex data and a \verb|GL_ELEMENT_ARRAY_BUFFER| to store the indices of the \verb|GL_ARRAY_BUFFER| that make up each face. However for ease of use in compute shaders I decided instead to store each face in a \verb|GL_SHADER_STORAGE_BUFFER|, where each face consists of three sets of positions, normals, and texture coordinates. Whilst this is less efficient, I found that the overhead in GPU memory usage was negligible, and that this method allowed for much simpler usage in a compute shader.












\subsection{User Testing} \label{sec:usertesting}
Near the end of the development I was able to convince friend and fellow student Alin Bolcas to test the system and provide feedback from an artist's point of view; Alin is an experienced modelling and look development artist who uses a variety of different software packages to create his work, so getting his feedback on the usability of my tool proved extremely useful.

His first comments were in regards to how the node graph handles rendering of meshes and curves; he found it quite unintuitive to manually create rendering nodes for each new curves object that needed to be drawn. He suggested that a node for the combination of curves should be added, which would consolidate multiple curve objects into a single output for simplified rendering.

He noted that the lack of a node that applies noise to curves proved problematic during his testing; this kind of node is fundamental to achieving appealing fur visuals. He liked the behaviour of the clumping node, as this functionality is also very common and highly used within fur systems, though visual quality was somewhat compromised as my current implementation does not preserve the initial curve length. Adding a control in the distributor that would allow for the variation of curve length was also suggested as something that would improve the quality of the visual output.

His final comments were in regards to the user interface, suggesting that I make controls similar to their counterparts in existing software wherever possible. Changing the camera controls to match those in Maya was suggested as it would provide a familiar user experience when manipulating the viewport. The ability to create new nodes by pressing the tab key as opposed to right click was also suggested, as this is the standard in node editors, such as those in Maya and Nuke.

\section{Results} \label{sec:results}
Results Text.

\subsection{Performance} \label{sec:performance}

insert stats comparing CPU/GPU compute

\section{Conclusion} \label{sec:conclusion}

\bibliographystyle{acmsiggraph}
\bibliography{references}

\end{document}
